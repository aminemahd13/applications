# Event Platform

A comprehensive, production-ready event management platform built with a modern tech stack.

## Tech Stack

- **Monorepo**: Turborepo
- **Frontend**: Next.js 14 (App Router)
- **Backend**: NestJS
- **Database**: PostgreSQL
- **ORM**: Prisma
- **Cache/Queue**: Redis
- **File Storage**: S3 Compatible (MinIO / AWS S3)
- **Authentication**: Session-based with Cookies
- **Language**: TypeScript

---

## üöÄ Production Quick Start

The easiest way to run the project in production is using Docker Compose. This setup includes the Application, Database, Redis, MinIO (S3 storage), and Nginx as a reverse proxy.

### 1. Prerequisites
- Docker & Docker Compose installed on your server.
- Basic knowledge of terminal commands.

### 2. Deployment Steps

1.  **Clone the Repository**
    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```

2.  **Configure Environment**
    Create a `.env` file in the root directory. You can copy the example:
    ```bash
    cp .env.example .env
    ```
    **Critical: Update the following security variables in `.env`:**
    - `POSTGRES_PASSWORD`: Set a strong password.
    - `MINIO_ROOT_USER` & `MINIO_ROOT_PASSWORD`: Set strong credentials for storage.
    - `JWT_SECRET`: Generate a random string (e.g., `openssl rand -hex 32`).
    - `SESSION_SECRET`: Generate a random string.
    - `SMTP_*`: Configure your email provider (see "Mail Configuration" below).

3.  **Build Images**
    ```bash
    docker-compose -f docker-compose.prod.yml build api web
    ```

4.  **Start Infrastructure First**
    ```bash
    docker-compose -f docker-compose.prod.yml up -d postgres redis minio
    ```

5.  **Run Production Migrations Manually**
    ```bash
    docker-compose -f docker-compose.prod.yml run --rm api sh -lc "./node_modules/.bin/prisma migrate deploy --schema packages/db/prisma/schema.prisma"
    ```

6.  **Run Seed Manually (Optional, Only If Needed)**
    ```bash
    docker-compose -f docker-compose.prod.yml run --rm api sh -lc "npm run -w packages/db seed"
    ```

7.  **Start Application Services**
    ```bash
    docker-compose -f docker-compose.prod.yml up -d api web
    ```

8.  **Verify Deployment**
    - **Frontend**: `http://<your-server-ip>`
    - **API**: `http://<your-server-ip>/api/v1/auth/me` (should return JSON, even when unauthenticated)
    - **MinIO Console**: `http://<your-server-ip>:9001` (If exposed in docker-compose, currently commented out for security).

---

## ‚öôÔ∏è Configuration & Environment Variables

The application is highly configurable via environment variables.

### Core Architecture
| Variable | Description | Default |
|----------|-------------|---------|
| `NODE_ENV` | Environment mode (`production`, `development`). | `development` |
| `PORT` | Port the service listens on internally. | `3000` |
| `DATABASE_URL` | PostgreSQL connection string. | `postgresql://...` |
| `REDIS_URL` | Redis connection string. | `redis://localhost:6379` |

### Security
| Variable | Description | Required? |
|----------|-------------|-----------|
| `JWT_SECRET` | Secret for signing JWTs (invites, resets). | **YES** |
| `SESSION_SECRET` | Secret for signing session cookies. | **YES** |
| `CORS_ORIGIN` | Allowed origin for CORS (e.g., `https://my-event-app.com`). | No (defaults to localhost) |
| `COOKIE_DOMAIN` | Domain for session cookies (e.g., `.my-event-app.com`). | No |

### üìÇ File Storage (S3 / MinIO)

The platform uses an S3-compatible driver. By default, the Docker setup uses **MinIO** so you don't need AWS.

**Using MinIO (Default Docker Setup):**
The `docker-compose.prod.yml` is pre-configured to use the internal `minio` container.
- `MINIO_ENDPOINT`: `minio` (internal docker hostname)
- `MINIO_PORT`: `9000`
- `MINIO_ACCESS_KEY`: Defined by `MINIO_ROOT_USER`
- `MINIO_SECRET_KEY`: Defined by `MINIO_ROOT_PASSWORD`
- `MINIO_BUCKET_NAME`: `uploads`

**Using AWS S3 (Production Alternative):**
To use real AWS S3, update your `.env`:
```env
# Remove MINIO_* specific vars or leave them unused
STORAGE_ENDPOINT=https://s3.amazonaws.com
STORAGE_REGION=us-east-1
STORAGE_ACCESS_KEY=your-aws-access-key
STORAGE_SECRET_KEY=your-aws-secret-key
STORAGE_BUCKET=your-bucket-name
```
The application prefers `STORAGE_*` variables if present, falling back to `MINIO_*` variables.

### üñºÔ∏è Public Assets

How images and static files are served.

| Variable | Description |
|----------|-------------|
| `NEXT_PUBLIC_ASSET_HOST` | Hostname for assets (e.g., `https://cdn.myapp.com`). If empty, uses relative paths proxied to API. |
| `NEXT_PUBLIC_DIRECT_ASSET_HOST` | Direct URL for assets if bypassing the proxy is needed. |

**How it works:**
1.  **Uploads**: User uploads a file -> API saves to MinIO/S3.
2.  **Serving**:
    -   **Private Files**: Served via signed URLs generated by the API.
    -   **Public Files**: Can be served directly from S3/MinIO or proxied through the API.
    -   If using MinIO locally, the Nginx proxy handles routing, so you generally don't need to change `NEXT_PUBLIC_ASSET_HOST`.

### üìß Mail Configuration (SMTP)

Required for sending invites, password resets, and notifications.

| Variable | Description |
|----------|-------------|
| `SMTP_HOST` | SMTP Server (e.g., `smtp.gmail.com`) |
| `SMTP_PORT` | SMTP Port (e.g., `587`) |
| `SMTP_USER` | SMTP Username |
| `SMTP_PASS` | SMTP Password |
| `SMTP_FROM` | Default "From" address |

---

## üèóÔ∏è Architecture Explained

### Docker Compose Services
- **`nginx`**: The gatekeeper. Listens on port 80.
    - Routes `/api/*` requests to the **API** container.
    - Routes all other requests to the **Web** container.
- **`web`**: Next.js frontend. Runs in standalone mode for performance.
- **`api`**: NestJS backend. Handles logic, database interactions, and storage.
- **`postgres`**: Relational database.
- **`redis`**: Key-value store for sessions and queues.
- **`minio`**: Object storage for files.

### Nginx Proxying
The `nginx.conf` is crucial. It allows running everything on a single domain without CORS issues.
- `https://domain.com/` -> served by Next.js
- `https://domain.com/api/v1/` -> served by NestJS

---

## üíª Development Setup

If you want to contribute or run locally without the full Docker stack:

1.  **Start Infrastructure**:
    ```bash
    docker-compose up -d postgres redis mino
    ```
2.  **Install Dependencies**:
    ```bash
    pnpm install
    ```
3.  **Sync Database**:
    ```bash
    pnpm db:generate
    pnpm db:migrate
    pnpm db:seed
    ```
4.  **Run Applications**:
    ```bash
    pnpm dev
    ```
    - `apps/web` running on `http://localhost:3000`
    - `apps/api` running on `http://localhost:3001`

---

## ‚ùì Troubleshooting

**1. "Connection Refused" between containers**
Ensure all services are on the same Docker network (`internal`). The compose file handles this automatically.

**2. Database Connection Fails**
Check that `DATABASE_URL` in the **API service** uses the docker service name (`postgres`) and not `localhost`.
- Correct: `postgres://user:pass@postgres:5432/db`
- Incorrect: `postgres://user:pass@localhost:5432/db`

**3. Files not uploading**
Check MinIO logs via `docker-compose -f docker-compose.prod.yml logs minio`. Ensure the bucket `uploads` exists (the API should create it automatically on startup if configured correctly, or you might need to create it manually in the MinIO console).

**4. Nginx 502 Bad Gateway**
The API or Web service might still be starting up. Check their logs:
```bash
docker-compose -f docker-compose.prod.yml logs -f api web
```
